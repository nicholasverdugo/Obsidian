# #Scikit-learn and an introduction to #Bayesian decision theory

## #Pandas functions

- df.info()
	- Gives a readout of every column's amount of values that are non-null, their data type, and other info
- df.corr(numeric_only=bool)['value_to_check_correlation_to'].sort_values(ascending=bool)
	- Gives how correlated each column value is to a given column value
	- That given column will always return 1 (as it is 100% correlated with itself)
- df['column'].hist(bins=x)
	- Creates a histogram with number of bins
	- Useful to visualize data spread in order to see if shuffling is required to select test and train sets
	- Good to select a number of bins that creates a usable visualization without smoothing out differences in data too much
- train_test_split
	- Allows separation of data into a train and test data set, can allow for shuffling
- imputer = SimpleImputer(strategy='strat')
	- strat can be median, mean, mode, etc
	- Useful to use the median to fill in missing values if there aren't many missing
	- after the imputer is set up, run imputer.fit(df)
	- This computes the *strat* for every column of the df
	- X = imputer.transform(df)
	- This fills missing values in
	- Use **fit_transform** to do these two functions in one command

## #Bayesian interpretation of the least squares estimator (w hat)

- 